{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79dbc81f",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "827d733c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q tf-keras\n",
    "%pip install -q transformers\n",
    "%pip install -q datasets\n",
    "%pip install -q nltk\n",
    "%pip install -q scikit-learn\n",
    "%pip install -q matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377243ac",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ab3d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Suppress TensorFlow deprecation warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373c94de",
   "metadata": {},
   "source": [
    "## 3. Load Dataset from JSONL Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f345f010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 72364\n",
      "Validation set size: 9045\n",
      "Testing set size: 9048\n"
     ]
    }
   ],
   "source": [
    "def load_jsonl(filepath):\n",
    "    \"\"\"Load data from JSONL file\"\"\"\n",
    "    data = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "# Load training, validation, and test datasets\n",
    "train_data = load_jsonl('dataset/train.jsonl')\n",
    "val_data = load_jsonl('dataset/val.jsonl')\n",
    "test_data = load_jsonl('dataset/test.jsonl')\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Testing set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63513a8e",
   "metadata": {},
   "source": [
    "## 4. Convert JSONL to DataFrame and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2f880e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample training data:\n",
      "                                                text  label\n",
      "0  මත්ද්‍රව්‍ය ජාවාරමකට සම්බන්ධ පුද්ගලයෙකු පොලිස්...     AI\n",
      "1  ශ්‍රී ලංකාවේ නව කැබිනට් මණ්ඩලයේ සංශෝධනය පිළිබඳ...     AI\n",
      "2  2012 පෙබරවාරි මාසයේ වැල්ලම්පිටියේ දී යුද හමුදා...  HUMAN\n",
      "3  (මනෝප්‍රිය ගුණසේකර)කතෝලික දේවස්ථාන හා තරුපහේ හ...  HUMAN\n",
      "4  මැතිවරණ කොමිසම වෙත මැතිවරණ ආශ්‍රිත පැමිණිලි 45...     AI\n",
      "\n",
      "Label value counts (Train):\n",
      "label\n",
      "HUMAN    39848\n",
      "AI       32516\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "train_df = pd.DataFrame(train_data)\n",
    "val_df = pd.DataFrame(val_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Display sample data\n",
    "print(\"Sample training data:\")\n",
    "print(train_df[['text', 'label']].head())\n",
    "print(f\"\\nLabel value counts (Train):\")\n",
    "print(train_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d1d0e8",
   "metadata": {},
   "source": [
    "## 5. Map Labels to Numeric Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0634946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Unmapped labels: 0\n",
      "Val - Unmapped labels: 0\n",
      "Test - Unmapped labels: 0\n"
     ]
    }
   ],
   "source": [
    "# Create label mapping\n",
    "label_mapping = {'HUMAN': 0, 'AI': 1}\n",
    "reverse_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Map labels to numeric values\n",
    "train_df['label_encoded'] = train_df['label'].map(label_mapping)\n",
    "val_df['label_encoded'] = val_df['label'].map(label_mapping)\n",
    "test_df['label_encoded'] = test_df['label'].map(label_mapping)\n",
    "\n",
    "# Check for any unmapped values\n",
    "print(f\"Train - Unmapped labels: {train_df['label_encoded'].isna().sum()}\")\n",
    "print(f\"Val - Unmapped labels: {val_df['label_encoded'].isna().sum()}\")\n",
    "print(f\"Test - Unmapped labels: {test_df['label_encoded'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c185608",
   "metadata": {},
   "source": [
    "## 6. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e02bf614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training data...\n",
      "Preprocessing validation data...\n",
      "Preprocessing validation data...\n",
      "Preprocessing test data...\n",
      "Preprocessing test data...\n",
      "Preprocessing complete!\n",
      "Preprocessing complete!\n"
     ]
    }
   ],
   "source": [
    "def expand_contractions(text):\n",
    "    \"\"\"Expand common English contractions\"\"\"\n",
    "    contractions = {\n",
    "        \"I'm\": \"I am\",\n",
    "        \"you're\": \"you are\",\n",
    "        \"he's\": \"he is\",\n",
    "        \"she's\": \"she is\",\n",
    "        \"it's\": \"it is\",\n",
    "        \"we're\": \"we are\",\n",
    "        \"they're\": \"they are\",\n",
    "        \"can't\": \"cannot\",\n",
    "        \"won't\": \"will not\",\n",
    "        \"didn't\": \"did not\",\n",
    "        \"doesn't\": \"does not\",\n",
    "        \"haven't\": \"have not\",\n",
    "        \"hasn't\": \"has not\",\n",
    "        \"hadn't\": \"had not\",\n",
    "        \"aren't\": \"are not\",\n",
    "        \"weren't\": \"were not\",\n",
    "        \"couldn't\": \"could not\",\n",
    "        \"shouldn't\": \"should not\",\n",
    "        \"wouldn't\": \"would not\",\n",
    "        \"gonna\": \"going to\"\n",
    "    }\n",
    "    \n",
    "    for contraction, expanded in contractions.items():\n",
    "        text = re.sub(r'\\b' + re.escape(contraction) + r'\\b', expanded, text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply text preprocessing\n",
    "print(\"Preprocessing training data...\")\n",
    "train_df['expanded_text'] = train_df['text'].apply(expand_contractions)\n",
    "\n",
    "print(\"Preprocessing validation data...\")\n",
    "val_df['expanded_text'] = val_df['text'].apply(expand_contractions)\n",
    "\n",
    "print(\"Preprocessing test data...\")\n",
    "test_df['expanded_text'] = test_df['text'].apply(expand_contractions)\n",
    "\n",
    "print(\"Preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000ce4ef",
   "metadata": {},
   "source": [
    "## 7. Load BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f100265c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileBERT tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load MobileBERT tokenizer (very lightweight model, ~150MB, supports multilingual)\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/mobilebert-uncased')\n",
    "print(\"MobileBERT tokenizer loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d474d1d",
   "metadata": {},
   "source": [
    "## 8. Tokenize and Encode Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52cb99b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data in batches...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Tokenize and encode the text data using tokenizer in batches to avoid memory spikes\n",
    "print(\"Tokenizing data in batches...\")\n",
    "\n",
    "def tokenize_in_batches(texts, tokenizer, batch_size=32, max_length=512):\n",
    "    \"\"\"Tokenize a list of texts in small batches and return numpy arrays.\n",
    "    Returns a dict with 'input_ids' and 'attention_mask' as numpy arrays.\n",
    "    Pads every batch to `max_length` so concatenation shapes match.\n",
    "    \"\"\"\n",
    "    input_ids_parts = []\n",
    "    attention_mask_parts = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(\n",
    "            batch,\n",
    "            padding='max_length',   # pad each batch to the fixed max_length\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        # Convert to numpy to keep memory usage predictable and avoid nested lists\n",
    "        ids = enc['input_ids'].numpy()\n",
    "        mask = enc['attention_mask'].numpy()\n",
    "\n",
    "        # Sanity check: ensure shape[1] == max_length\n",
    "        if ids.shape[1] != max_length:\n",
    "            # If tokenizer produced a different length for some reason, force-pad/truncate\n",
    "            ids = np.pad(ids, ((0,0),(0,max_length-ids.shape[1])), constant_values=0)[:,:max_length]\n",
    "            mask = np.pad(mask, ((0,0),(0,max_length-mask.shape[1])), constant_values=0)[:,:max_length]\n",
    "\n",
    "        input_ids_parts.append(ids)\n",
    "        attention_mask_parts.append(mask)\n",
    "\n",
    "    input_ids = np.concatenate(input_ids_parts, axis=0)\n",
    "    attention_mask = np.concatenate(attention_mask_parts, axis=0)\n",
    "\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "# Run batched tokenization\n",
    "train_encodings = tokenize_in_batches(train_df['expanded_text'].tolist(), tokenizer, batch_size=32)\n",
    "val_encodings = tokenize_in_batches(val_df['expanded_text'].tolist(), tokenizer, batch_size=32)\n",
    "test_encodings = tokenize_in_batches(test_df['expanded_text'].tolist(), tokenizer, batch_size=32)\n",
    "\n",
    "print(\"Tokenization complete!\")\n",
    "print(f\"Training encodings shape: {train_encodings['input_ids'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c7630",
   "metadata": {},
   "source": [
    "## 9. Prepare Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b2bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels shape: (72364,)\n",
      "Val labels shape: (9045,)\n",
      "Test labels shape: (9048,)\n",
      "\n",
      "Label distribution (Train): [39848 32516]\n",
      "Label distribution (Val): [4981 4064]\n",
      "Label distribution (Test): [4982 4066]\n"
     ]
    }
   ],
   "source": [
    "# Extract input arrays and convert labels to numpy arrays\n",
    "# Use dicts with both input_ids and attention_mask so the model gets both inputs\n",
    "train_inputs = {\n",
    "    'input_ids': train_encodings['input_ids'],\n",
    "    'attention_mask': train_encodings['attention_mask']\n",
    "}\n",
    "val_inputs = {\n",
    "    'input_ids': val_encodings['input_ids'],\n",
    "    'attention_mask': val_encodings['attention_mask']\n",
    "}\n",
    "test_inputs = {\n",
    "    'input_ids': test_encodings['input_ids'],\n",
    "    'attention_mask': test_encodings['attention_mask']\n",
    "}\n",
    "\n",
    "# Convert labels to numpy arrays\n",
    "train_labels = np.array(train_df['label_encoded'].astype(int).tolist())\n",
    "val_labels = np.array(val_df['label_encoded'].astype(int).tolist())\n",
    "test_labels = np.array(test_df['label_encoded'].astype(int).tolist())\n",
    "\n",
    "print(f\"Train labels shape: {train_labels.shape}\")\n",
    "print(f\"Val labels shape: {val_labels.shape}\")\n",
    "print(f\"Test labels shape: {test_labels.shape}\")\n",
    "print(f\"\\nLabel distribution (Train): {np.bincount(train_labels)}\")\n",
    "print(f\"Label distribution (Val): {np.bincount(val_labels)}\")\n",
    "print(f\"Label distribution (Test): {np.bincount(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4522d808",
   "metadata": {},
   "source": [
    "## 10. Define BERT Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a167267a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "The paging file is too small for this operation to complete. (os error 1455)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load pre-trained DistilBERT model for sequence classification (lighter version)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TFDistilBertForSequenceClassification\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model = \u001b[43mTFDistilBertForSequenceClassification\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdistilbert-base-multilingual-cased\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Binary classification: HUMAN (0) vs AI (1)\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDistilBERT model loaded successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Pasindu Gunarathne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:2903\u001b[39m, in \u001b[36mTFPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[39m\n\u001b[32m   2901\u001b[39m safetensors_from_pt = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2902\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename == SAFE_WEIGHTS_NAME:\n\u001b[32m-> \u001b[39m\u001b[32m2903\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msafe_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m   2904\u001b[39m         safetensors_metadata = f.metadata()\n\u001b[32m   2905\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m safetensors_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m safetensors_metadata.get(\u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mflax\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmlx\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[31mOSError\u001b[39m: The paging file is too small for this operation to complete. (os error 1455)"
     ]
    }
   ],
   "source": [
    "# Load pre-trained MobileBERT model for sequence classification (very lightweight, ~150MB)\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    'google/mobilebert-uncased',\n",
    "    num_labels=2  # Binary classification: HUMAN (0) vs AI (1)\n",
    ")\n",
    "\n",
    "print(\"MobileBERT model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d250e44",
   "metadata": {},
   "source": [
    "## 11. Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9b0ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=[metric]\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")\n",
    "print(\"\\nModel Summary:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8112c1b3",
   "metadata": {},
   "source": [
    "## 12. Train the BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a31721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the BERT model\n",
    "print(\"Training the model...\")\n",
    "history = model.fit(\n",
    "    train_inputs,\n",
    "    train_labels,\n",
    "    epochs=3,  # Reduced epochs due to large dataset size\n",
    "    batch_size=16,\n",
    "    validation_data=(val_inputs, val_labels),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97901106",
   "metadata": {},
   "source": [
    "## 13. Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05db1261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire trained model\n",
    "model.save_pretrained(\"models/bert_multilingual/\")\n",
    "print(\"Model saved to models/bert_multilingual/\")\n",
    "\n",
    "# Also save the tokenizer\n",
    "tokenizer.save_pretrained(\"models/bert_multilingual/\")\n",
    "print(\"Tokenizer saved to models/bert_multilingual/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fecc48",
   "metadata": {},
   "source": [
    "## 14. Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df445294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(val_inputs, val_labels, verbose=0)\n",
    "print(f'Validation Loss: {val_loss:.4f}')\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4da967e",
   "metadata": {},
   "source": [
    "## 15. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c909ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_labels, verbose=0)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33de3bbf",
   "metadata": {},
   "source": [
    "## 16. Plot Training and Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154ed454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "plt.title('Training and Validation Accuracy', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "plt.title('Training and Validation Loss', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/training_history.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training history plot saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b3020",
   "metadata": {},
   "source": [
    "## 17. Generate Predictions and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for the test set\n",
    "predictions = model.predict(test_inputs)\n",
    "predicted_labels = np.argmax(predictions.logits, axis=1)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(test_labels, predicted_labels)\n",
    "\n",
    "# Display confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['HUMAN', 'AI'])\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "plt.title('Confusion Matrix - BERT Text Classification', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/confusion_matrix.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion matrix saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c611a06",
   "metadata": {},
   "source": [
    "## 18. Calculate ROC Curve and AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aea5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities for positive class (AI)\n",
    "probabilities = tf.nn.softmax(predictions.logits)[:, 1]\n",
    "\n",
    "# Calculate AUC score\n",
    "auc_score = roc_auc_score(test_labels, probabilities)\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(test_labels, probabilities)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc_score:.4f}', linewidth=2, color='blue')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - BERT Text Classification', fontsize=12, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/roc_curve.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f22a2a",
   "metadata": {},
   "source": [
    "## 19. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be61bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate detailed classification report\n",
    "report = classification_report(\n",
    "    test_labels, \n",
    "    predicted_labels, \n",
    "    target_names=['HUMAN', 'AI'],\n",
    "    digits=4\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT - TEST SET\")\n",
    "print(\"=\"*60)\n",
    "print(report)\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8c27ee",
   "metadata": {},
   "source": [
    "## 20. Summary of Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a477257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary of model performance\n",
    "summary_data = {\n",
    "    'Metric': ['Test Accuracy', 'Test Loss', 'AUC Score'],\n",
    "    'Value': [f'{test_accuracy:.4f}', f'{test_loss:.4f}', f'{auc_score:.4f}']\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv('results/model_performance_summary.csv', index=False)\n",
    "print(\"\\nPerformance summary saved to results/model_performance_summary.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
