{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24bbc111",
   "metadata": {},
   "source": [
    "# XLM-RoBERTa Text Classifier for Sinhala AI/Human Detection\n",
    "\n",
    "This notebook implements a text classification model using XLM-RoBERTa (Cross-lingual Language Model - RoBERTa) for detecting AI-generated vs Human-written Sinhala text. XLM-RoBERTa is specifically designed for multilingual tasks and performs excellently with low-resource languages like Sinhala."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb435025",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b6b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q tf-keras\n",
    "%pip install -q transformers\n",
    "%pip install -q datasets\n",
    "%pip install -q nltk\n",
    "%pip install -q scikit-learn\n",
    "%pip install -q matplotlib\n",
    "%pip install -q sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a5b499",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19943840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Suppress TensorFlow deprecation warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acc9cbf",
   "metadata": {},
   "source": [
    "## 3. Load Dataset from JSONL Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0999234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(filepath):\n",
    "    \"\"\"Load data from JSONL file\"\"\"\n",
    "    data = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "# Load training, validation, and test datasets\n",
    "train_data = load_jsonl('dataset/train.jsonl')\n",
    "val_data = load_jsonl('dataset/val.jsonl')\n",
    "test_data = load_jsonl('dataset/test.jsonl')\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Testing set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5138036f",
   "metadata": {},
   "source": [
    "## 4. Convert JSONL to DataFrame and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c5f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "train_df = pd.DataFrame(train_data)\n",
    "val_df = pd.DataFrame(val_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Display sample data\n",
    "print(\"Sample training data:\")\n",
    "print(train_df[['text', 'label']].head())\n",
    "print(f\"\\nLabel value counts (Train):\")\n",
    "print(train_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a4af16",
   "metadata": {},
   "source": [
    "## 5. Map Labels to Numeric Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bec6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label mapping\n",
    "label_mapping = {'HUMAN': 0, 'AI': 1}\n",
    "reverse_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Map labels to numeric values\n",
    "train_df['label_encoded'] = train_df['label'].map(label_mapping)\n",
    "val_df['label_encoded'] = val_df['label'].map(label_mapping)\n",
    "test_df['label_encoded'] = test_df['label'].map(label_mapping)\n",
    "\n",
    "# Check for any unmapped values\n",
    "print(f\"Train - Unmapped labels: {train_df['label_encoded'].isna().sum()}\")\n",
    "print(f\"Val - Unmapped labels: {val_df['label_encoded'].isna().sum()}\")\n",
    "print(f\"Test - Unmapped labels: {test_df['label_encoded'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ec5d4e",
   "metadata": {},
   "source": [
    "## 6. Text Preprocessing\n",
    "\n",
    "XLM-RoBERTa handles multilingual text well, but we'll still apply Sinhala-specific normalization for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a8054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "# Sinhala-focused normalization & contraction expansion\n",
    "\n",
    "def expand_contractions(text):\n",
    "    \"\"\"\n",
    "    Normalize Sinhala text and expand a small set of common colloquial contractions.\n",
    "    - NFC Unicode normalization (avoids mixed composition forms)\n",
    "    - Remove Zero-Width Joiner/Non-Joiner which can appear in Sinhala typing\n",
    "    - Expand a curated list of common colloquial forms to their standard forms\n",
    "    Note: This list is intentionally conservative to avoid changing semantics.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    # Normalize to NFC to standardize diacritics\n",
    "    text = unicodedata.normalize('NFC', text)\n",
    "\n",
    "    # Remove zero-width characters often accidentally present\n",
    "    text = text.replace('\\u200c', '').replace('\\u200d', '')  # ZWNJ/ZWJ\n",
    "\n",
    "    # Conservative Sinhala \"contractions\" / colloquial expansions\n",
    "    contractions_si = {\n",
    "        # Negation forms\n",
    "        'නෑ': 'නැහැ',\n",
    "        'බෑ': 'බැහැ',\n",
    "        # Colloquial vowels / emphasis\n",
    "        'දැං': 'දැන්',\n",
    "        'කොහේද': 'කොහෙද',\n",
    "        'මොකෝ': 'මොකද',\n",
    "        # Common short forms ending with \"ෙ\" to \"ේ\" (targeted words only)\n",
    "        'ඇතුලෙ': 'ඇතුලේ',\n",
    "        'බාහිරෙ': 'බාහිරේ',\n",
    "        'වැඩෙ': 'වැඩේ',\n",
    "        'රජයෙ': 'රජයේ',\n",
    "        'යාලුවෙ': 'යාලුවේ',\n",
    "    }\n",
    "\n",
    "    # Apply word-boundary replacements for items above\n",
    "    for contraction, expanded in contractions_si.items():\n",
    "        text = re.sub(r\"\\b\" + re.escape(contraction) + r\"\\b\", expanded, text)\n",
    "\n",
    "    # Targeted possessive expansions (avoid generic \"ගෙ\" → \"ගේ\" to not corrupt 'ගෙදර')\n",
    "    text = re.sub(r\"\\bමගෙ\\b\", \"මගේ\", text)\n",
    "    text = re.sub(r\"\\bඔයාගෙ\\b\", \"ඔයාගේ\", text)\n",
    "    text = re.sub(r\"\\bඔගෙ\\b\", \"ඔගේ\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply expansion of contractions using Sinhala-focused normalization\n",
    "print(\"Preprocessing training data (Sinhala normalization)...\")\n",
    "train_df['expanded_text'] = train_df['text'].apply(expand_contractions)\n",
    "\n",
    "print(\"Preprocessing validation data (Sinhala normalization)...\")\n",
    "val_df['expanded_text'] = val_df['text'].apply(expand_contractions)\n",
    "\n",
    "print(\"Preprocessing test data (Sinhala normalization)...\")\n",
    "test_df['expanded_text'] = test_df['text'].apply(expand_contractions)\n",
    "\n",
    "print(\"Preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8905a1",
   "metadata": {},
   "source": [
    "## 7. Load XLM-RoBERTa Tokenizer\n",
    "\n",
    "XLM-RoBERTa is trained on 100 languages including Sinhala. We'll use the base model (~560MB) which provides excellent multilingual performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3204ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load XLM-RoBERTa tokenizer\n",
    "model_name = 'xlm-roberta-base'  # ~560MB, supports 100 languages including Sinhala\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print(f\"XLM-RoBERTa tokenizer loaded successfully from {model_name}!\")\n",
    "print(f\"Tokenizer vocab size: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04af91b",
   "metadata": {},
   "source": [
    "## 8. Tokenize and Encode Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca122ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode the text data using tokenizer in batches to avoid memory spikes\n",
    "print(\"Tokenizing data in batches...\")\n",
    "\n",
    "def tokenize_in_batches(texts, tokenizer, batch_size=32, max_length=512):\n",
    "    \"\"\"Tokenize a list of texts in small batches and return numpy arrays.\n",
    "    Returns a dict with 'input_ids' and 'attention_mask' as numpy arrays.\n",
    "    Pads every batch to `max_length` so concatenation shapes match.\n",
    "    \"\"\"\n",
    "    input_ids_parts = []\n",
    "    attention_mask_parts = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(\n",
    "            batch,\n",
    "            padding='max_length',   # pad each batch to the fixed max_length\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        # Convert to numpy to keep memory usage predictable and avoid nested lists\n",
    "        ids = enc['input_ids'].numpy()\n",
    "        mask = enc['attention_mask'].numpy()\n",
    "\n",
    "        # Sanity check: ensure shape[1] == max_length\n",
    "        if ids.shape[1] != max_length:\n",
    "            # If tokenizer produced a different length for some reason, force-pad/truncate\n",
    "            ids = np.pad(ids, ((0,0),(0,max_length-ids.shape[1])), constant_values=0)[:,:max_length]\n",
    "            mask = np.pad(mask, ((0,0),(0,max_length-mask.shape[1])), constant_values=0)[:,:max_length]\n",
    "\n",
    "        input_ids_parts.append(ids)\n",
    "        attention_mask_parts.append(mask)\n",
    "\n",
    "    input_ids = np.concatenate(input_ids_parts, axis=0)\n",
    "    attention_mask = np.concatenate(attention_mask_parts, axis=0)\n",
    "\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "# Run batched tokenization\n",
    "train_encodings = tokenize_in_batches(train_df['expanded_text'].tolist(), tokenizer, batch_size=32)\n",
    "val_encodings = tokenize_in_batches(val_df['expanded_text'].tolist(), tokenizer, batch_size=32)\n",
    "test_encodings = tokenize_in_batches(test_df['expanded_text'].tolist(), tokenizer, batch_size=32)\n",
    "\n",
    "print(\"Tokenization complete!\")\n",
    "print(f\"Training encodings shape: {train_encodings['input_ids'].shape}\")\n",
    "print(f\"Validation encodings shape: {val_encodings['input_ids'].shape}\")\n",
    "print(f\"Test encodings shape: {test_encodings['input_ids'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce058cd1",
   "metadata": {},
   "source": [
    "## 9. Prepare Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9941e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract input arrays and convert labels to numpy arrays\n",
    "# Use dicts with both input_ids and attention_mask so the model gets both inputs\n",
    "train_inputs = {\n",
    "    'input_ids': train_encodings['input_ids'],\n",
    "    'attention_mask': train_encodings['attention_mask']\n",
    "}\n",
    "val_inputs = {\n",
    "    'input_ids': val_encodings['input_ids'],\n",
    "    'attention_mask': val_encodings['attention_mask']\n",
    "}\n",
    "test_inputs = {\n",
    "    'input_ids': test_encodings['input_ids'],\n",
    "    'attention_mask': test_encodings['attention_mask']\n",
    "}\n",
    "\n",
    "# Convert labels to numpy arrays\n",
    "train_labels = np.array(train_df['label_encoded'].astype(int).tolist())\n",
    "val_labels = np.array(val_df['label_encoded'].astype(int).tolist())\n",
    "test_labels = np.array(test_df['label_encoded'].astype(int).tolist())\n",
    "\n",
    "print(f\"Train labels shape: {train_labels.shape}\")\n",
    "print(f\"Val labels shape: {val_labels.shape}\")\n",
    "print(f\"Test labels shape: {test_labels.shape}\")\n",
    "print(f\"\\nLabel distribution (Train): {np.bincount(train_labels)}\")\n",
    "print(f\"Label distribution (Val): {np.bincount(val_labels)}\")\n",
    "print(f\"Label distribution (Test): {np.bincount(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf3d24b",
   "metadata": {},
   "source": [
    "## 10. Define XLM-RoBERTa Classification Model\n",
    "\n",
    "Loading the pre-trained XLM-RoBERTa model for sequence classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028cb432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained XLM-RoBERTa model for sequence classification\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2  # Binary classification: HUMAN (0) vs AI (1)\n",
    ")\n",
    "\n",
    "print(f\"XLM-RoBERTa model loaded successfully from {model_name}!\")\n",
    "print(f\"Model has {model.num_parameters():,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fec05d",
   "metadata": {},
   "source": [
    "## 11. Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542dc630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with appropriate optimizer and loss function\n",
    "# Using a slightly lower learning rate for XLM-RoBERTa\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=[metric]\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")\n",
    "print(\"\\nModel Summary:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1273182",
   "metadata": {},
   "source": [
    "## 12. Train the XLM-RoBERTa Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a80304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the XLM-RoBERTa model\n",
    "print(\"Training the XLM-RoBERTa model...\")\n",
    "print(\"This may take some time depending on your hardware.\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_inputs,\n",
    "    train_labels,\n",
    "    epochs=3,  # 3 epochs is typical for fine-tuning transformer models\n",
    "    batch_size=16,  # Adjust based on available GPU memory\n",
    "    validation_data=(val_inputs, val_labels),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14b6193",
   "metadata": {},
   "source": [
    "## 13. Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe207fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(\"models/xlm_roberta_classifier\", exist_ok=True)\n",
    "\n",
    "# Save the entire trained model\n",
    "model.save_pretrained(\"models/xlm_roberta_classifier/\")\n",
    "print(\"Model saved to models/xlm_roberta_classifier/\")\n",
    "\n",
    "# Also save the tokenizer\n",
    "tokenizer.save_pretrained(\"models/xlm_roberta_classifier/\")\n",
    "print(\"Tokenizer saved to models/xlm_roberta_classifier/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2e4d7",
   "metadata": {},
   "source": [
    "## 14. Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4b2f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "print(\"Evaluating on validation set...\")\n",
    "val_loss, val_accuracy = model.evaluate(val_inputs, val_labels, verbose=0)\n",
    "print(f'Validation Loss: {val_loss:.4f}')\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f532217",
   "metadata": {},
   "source": [
    "## 15. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f8246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_labels, verbose=0)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd0f318",
   "metadata": {},
   "source": [
    "## 16. Plot Training and Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b171b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory if it doesn't exist\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# Plot accuracy and loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2, marker='o')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2, marker='s')\n",
    "plt.title('XLM-RoBERTa: Training and Validation Accuracy', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss', linewidth=2, marker='o')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2, marker='s')\n",
    "plt.title('XLM-RoBERTa: Training and Validation Loss', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/xlm_roberta_training_history.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training history plot saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a825a0",
   "metadata": {},
   "source": [
    "## 17. Generate Predictions and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677abbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for the test set\n",
    "print(\"Generating predictions on test set...\")\n",
    "predictions = model.predict(test_inputs)\n",
    "predicted_labels = np.argmax(predictions.logits, axis=1)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(test_labels, predicted_labels)\n",
    "\n",
    "# Display confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['HUMAN', 'AI'])\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "plt.title('Confusion Matrix - XLM-RoBERTa Text Classification', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/xlm_roberta_confusion_matrix.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion matrix saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c4154",
   "metadata": {},
   "source": [
    "## 18. Calculate ROC Curve and AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f237cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities for positive class (AI)\n",
    "probabilities = tf.nn.softmax(predictions.logits)[:, 1]\n",
    "\n",
    "# Calculate AUC score\n",
    "auc_score = roc_auc_score(test_labels, probabilities)\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(test_labels, probabilities)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'XLM-RoBERTa (AUC = {auc_score:.4f})', linewidth=2, color='darkgreen')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate', fontsize=11)\n",
    "plt.ylabel('True Positive Rate', fontsize=11)\n",
    "plt.title('ROC Curve - XLM-RoBERTa Text Classification', fontsize=12, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/xlm_roberta_roc_curve.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0175ffa",
   "metadata": {},
   "source": [
    "## 19. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ee436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate detailed classification report\n",
    "report = classification_report(\n",
    "    test_labels,\n",
    "    predicted_labels,\n",
    "    target_names=['HUMAN', 'AI'],\n",
    "    digits=4\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT - TEST SET (XLM-RoBERTa)\")\n",
    "print(\"=\"*60)\n",
    "print(report)\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510ae65f",
   "metadata": {},
   "source": [
    "## 20. Summary of Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81697af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary of model performance\n",
    "summary_data = {\n",
    "    'Metric': ['Test Accuracy', 'Test Loss', 'AUC Score', 'Model Size', 'Parameters'],\n",
    "    'Value': [\n",
    "        f'{test_accuracy:.4f}',\n",
    "        f'{test_loss:.4f}',\n",
    "        f'{auc_score:.4f}',\n",
    "        '~560MB',\n",
    "        f'{model.num_parameters():,}'\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"XLM-RoBERTa MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv('results/xlm_roberta_performance_summary.csv', index=False)\n",
    "print(\"\\nPerformance summary saved to results/xlm_roberta_performance_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b8b119",
   "metadata": {},
   "source": [
    "## 21. Test the Model with Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc45e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Predict whether a given text is AI-generated or Human-written\n",
    "    \"\"\"\n",
    "    # Preprocess the text\n",
    "    processed_text = expand_contractions(text)\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        processed_text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict({\n",
    "        'input_ids': inputs['input_ids'],\n",
    "        'attention_mask': inputs['attention_mask']\n",
    "    }, verbose=0)\n",
    "    \n",
    "    # Get probabilities\n",
    "    probs = tf.nn.softmax(predictions.logits)[0]\n",
    "    predicted_label = np.argmax(probs)\n",
    "    \n",
    "    return {\n",
    "        'label': reverse_mapping[predicted_label],\n",
    "        'human_prob': float(probs[0]),\n",
    "        'ai_prob': float(probs[1]),\n",
    "        'confidence': float(probs[predicted_label])\n",
    "    }\n",
    "\n",
    "# Test with sample texts from test set\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAMPLE PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "sample_indices = [0, 10, 20, 30, 40]\n",
    "for idx in sample_indices:\n",
    "    if idx < len(test_df):\n",
    "        text = test_df.iloc[idx]['text']\n",
    "        true_label = test_df.iloc[idx]['label']\n",
    "        \n",
    "        result = predict_text(text, model, tokenizer)\n",
    "        \n",
    "        print(f\"\\nText: {text[:100]}...\")\n",
    "        print(f\"True Label: {true_label}\")\n",
    "        print(f\"Predicted: {result['label']} (Confidence: {result['confidence']:.2%})\")\n",
    "        print(f\"Human Prob: {result['human_prob']:.2%} | AI Prob: {result['ai_prob']:.2%}\")\n",
    "        print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edea2749",
   "metadata": {},
   "source": [
    "## 22. Model Comparison Notes\n",
    "\n",
    "### XLM-RoBERTa vs MobileBERT:\n",
    "\n",
    "**XLM-RoBERTa Advantages:**\n",
    "- Better multilingual support (trained on 100 languages)\n",
    "- Stronger performance on low-resource languages like Sinhala\n",
    "- More robust to linguistic variations\n",
    "- Better contextual understanding\n",
    "\n",
    "**XLM-RoBERTa Considerations:**\n",
    "- Larger model size (~560MB vs ~150MB for MobileBERT)\n",
    "- Slightly slower inference time\n",
    "- Requires more GPU memory during training\n",
    "\n",
    "**Best Use Cases:**\n",
    "- Use XLM-RoBERTa for maximum accuracy on Sinhala text\n",
    "- Use MobileBERT for resource-constrained environments or mobile deployment"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
