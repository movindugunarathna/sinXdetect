{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe24d41c",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/movindugunarathna/sinXdetect/blob/main/ml/sinbert_text_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fe744d",
   "metadata": {},
   "source": [
    "# SinBERT Text Classifier for Sinhala AI Detection\n",
    "\n",
    "This notebook implements a text classification model using NLPC-UOM's SinBERT-large model to detect AI-generated Sinhala text. SinBERT is specifically trained on Sinhala language data, making it potentially more effective for Sinhala text classification tasks compared to multilingual models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c5664",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64342b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q tf-keras\n",
    "%pip install -q transformers\n",
    "%pip install -q datasets\n",
    "%pip install -q nltk\n",
    "%pip install -q scikit-learn\n",
    "%pip install -q matplotlib\n",
    "%pip install -q seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4723103",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50044b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    precision_recall_curve,\n",
    "    f1_score\n",
    ")\n",
    "import re\n",
    "import unicodedata\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Suppress TensorFlow warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TFAutoModelForSequenceClassification,\n",
    "    AutoConfig\n",
    ")\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cf30e0",
   "metadata": {},
   "source": [
    "## 3. Load Dataset from JSONL Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382b9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "def load_jsonl(filepath):\n",
    "    \"\"\"Load data from JSONL file\"\"\"\n",
    "    data = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "# Define the path to the dataset in Google Drive\n",
    "# Update this path based on where you stored the 'dataset' folder in your Drive\n",
    "drive_base_path = '/content/drive/MyDrive/Colab Notebooks/sinxdetect/dataset'\n",
    "\n",
    "# Load training, validation, and test datasets\n",
    "train_data = load_jsonl(os.path.join(drive_base_path, 'train.jsonl'))\n",
    "val_data = load_jsonl(os.path.join(drive_base_path, 'val.jsonl'))\n",
    "test_data = load_jsonl(os.path.join(drive_base_path, 'test.jsonl'))\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Testing set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa43077",
   "metadata": {},
   "source": [
    "## 4. Convert to DataFrame and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a464cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "train_df = pd.DataFrame(train_data)\n",
    "val_df = pd.DataFrame(val_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Display sample data\n",
    "print(\"Sample training data:\")\n",
    "print(train_df[['text', 'label']].head())\n",
    "print(f\"\\nLabel distribution (Train):\")\n",
    "print(train_df['label'].value_counts())\n",
    "print(f\"\\nLabel distribution (Validation):\")\n",
    "print(val_df['label'].value_counts())\n",
    "print(f\"\\nLabel distribution (Test):\")\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b98473",
   "metadata": {},
   "source": [
    "## 5. Map Labels to Numeric Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb31eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label mapping\n",
    "label_mapping = {'HUMAN': 0, 'AI': 1}\n",
    "reverse_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Map labels to numeric values\n",
    "train_df['label_encoded'] = train_df['label'].map(label_mapping)\n",
    "val_df['label_encoded'] = val_df['label'].map(label_mapping)\n",
    "test_df['label_encoded'] = test_df['label'].map(label_mapping)\n",
    "\n",
    "# Check for any unmapped values\n",
    "print(f\"Train - Unmapped labels: {train_df['label_encoded'].isna().sum()}\")\n",
    "print(f\"Val - Unmapped labels: {val_df['label_encoded'].isna().sum()}\")\n",
    "print(f\"Test - Unmapped labels: {test_df['label_encoded'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca80fefb",
   "metadata": {},
   "source": [
    "## 6. Sinhala Text Preprocessing\n",
    "\n",
    "**Important Note:** SinBERT was trained specifically on Sinhala text and its tokenizer is designed to handle Sinhala linguistic variations. We apply minimal preprocessing to preserve the natural text patterns that SinBERT was trained on. This is different from multilingual models that may benefit from more aggressive normalization.\n",
    "\n",
    "Based on the word cloud analysis, common Sinhala words in the dataset include: මම, ඔබ, කළ, වන, සිංහල, කරන, etc. We preserve these natural forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6652ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sinhala_text(text):\n",
    "    \"\"\"\n",
    "    Minimal Sinhala text preprocessing optimized for SinBERT:\n",
    "    - NFC Unicode normalization (essential for consistency)\n",
    "    - Clean extra whitespace\n",
    "    - Preserve natural Sinhala variations (SinBERT's tokenizer handles these)\n",
    "    \n",
    "    Note: We avoid aggressive normalization (contractions, zero-width chars, etc.) \n",
    "    because SinBERT was trained on natural Sinhala text with these variations.\n",
    "    Removing them may hurt performance.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    # Normalize to NFC (Canonical Composition) - Essential for Unicode consistency\n",
    "    text = unicodedata.normalize('NFC', text)\n",
    "\n",
    "    # Clean extra whitespace and newlines\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Remove any unusual control characters (but keep common Sinhala ones)\n",
    "    # Keep ZWNJ (U+200C) and ZWJ (U+200D) as they're part of proper Sinhala orthography\n",
    "    text = re.sub(r'[\\x00-\\x08\\x0B-\\x0C\\x0E-\\x1F\\x7F-\\x9F]', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"Preprocessing training data...\")\n",
    "train_df['processed_text'] = train_df['text'].apply(preprocess_sinhala_text)\n",
    "\n",
    "print(\"Preprocessing validation data...\")\n",
    "val_df['processed_text'] = val_df['text'].apply(preprocess_sinhala_text)\n",
    "\n",
    "print(\"Preprocessing test data...\")\n",
    "test_df['processed_text'] = test_df['text'].apply(preprocess_sinhala_text)\n",
    "\n",
    "print(\"\\nPreprocessing complete!\")\n",
    "print(f\"\\nExample preprocessed text:\")\n",
    "print(f\"Original: {train_df['text'].iloc[0][:100]}...\")\n",
    "print(f\"Processed: {train_df['processed_text'].iloc[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa35850",
   "metadata": {},
   "source": [
    "## 7. Load SinBERT Tokenizer\n",
    "\n",
    "We use `NLPC-UOM/SinBERT-large` which is specifically trained on Sinhala language data. This model should provide better performance for Sinhala text classification compared to multilingual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de193a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SinBERT tokenizer\n",
    "MODEL_NAME = 'NLPC-UOM/SinBERT-large'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "print(f\"✓ SinBERT tokenizer loaded: {MODEL_NAME}\")\n",
    "print(f\"Vocabulary size: {tokenizer.vocab_size}\")\n",
    "print(f\"Max length: {tokenizer.model_max_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110cbd9d",
   "metadata": {},
   "source": [
    "## 8. Tokenize and Encode Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dce2538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MAX_LENGTH = 256  # Optimal for most Sinhala text\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def tokenize_in_batches(texts, tokenizer, batch_size=32, max_length=256):\n",
    "    \"\"\"\n",
    "    Tokenize texts in batches to manage memory efficiently.\n",
    "    Returns dict with 'input_ids' and 'attention_mask' as numpy arrays.\n",
    "    \"\"\"\n",
    "    input_ids_parts = []\n",
    "    attention_mask_parts = []\n",
    "\n",
    "    total_batches = (len(texts) + batch_size - 1) // batch_size\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "\n",
    "        # Tokenize batch\n",
    "        enc = tokenizer(\n",
    "            batch,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "\n",
    "        # Convert to numpy\n",
    "        ids = enc['input_ids'].numpy()\n",
    "        mask = enc['attention_mask'].numpy()\n",
    "\n",
    "        input_ids_parts.append(ids)\n",
    "        attention_mask_parts.append(mask)\n",
    "\n",
    "        if (i // batch_size + 1) % 10 == 0:\n",
    "            print(f\"  Processed {i // batch_size + 1}/{total_batches} batches\")\n",
    "\n",
    "    # Concatenate all batches\n",
    "    input_ids = np.concatenate(input_ids_parts, axis=0)\n",
    "    attention_mask = np.concatenate(attention_mask_parts, axis=0)\n",
    "\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "# Tokenize datasets\n",
    "print(\"Tokenizing training data...\")\n",
    "train_encodings = tokenize_in_batches(\n",
    "    train_df['processed_text'].tolist(),\n",
    "    tokenizer,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_length=MAX_LENGTH\n",
    ")\n",
    "\n",
    "print(\"\\nTokenizing validation data...\")\n",
    "val_encodings = tokenize_in_batches(\n",
    "    val_df['processed_text'].tolist(),\n",
    "    tokenizer,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_length=MAX_LENGTH\n",
    ")\n",
    "\n",
    "print(\"\\nTokenizing test data...\")\n",
    "test_encodings = tokenize_in_batches(\n",
    "    test_df['processed_text'].tolist(),\n",
    "    tokenizer,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_length=MAX_LENGTH\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Tokenization complete!\")\n",
    "print(f\"Training encodings shape: {train_encodings['input_ids'].shape}\")\n",
    "print(f\"Validation encodings shape: {val_encodings['input_ids'].shape}\")\n",
    "print(f\"Test encodings shape: {test_encodings['input_ids'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c0fbd5",
   "metadata": {},
   "source": [
    "## 9. Prepare Input Data and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f8e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input dictionaries\n",
    "train_inputs = {\n",
    "    'input_ids': train_encodings['input_ids'],\n",
    "    'attention_mask': train_encodings['attention_mask']\n",
    "}\n",
    "\n",
    "val_inputs = {\n",
    "    'input_ids': val_encodings['input_ids'],\n",
    "    'attention_mask': val_encodings['attention_mask']\n",
    "}\n",
    "\n",
    "test_inputs = {\n",
    "    'input_ids': test_encodings['input_ids'],\n",
    "    'attention_mask': test_encodings['attention_mask']\n",
    "}\n",
    "\n",
    "# Prepare labels\n",
    "train_labels = np.array(train_df['label_encoded'].astype(int).tolist())\n",
    "val_labels = np.array(val_df['label_encoded'].astype(int).tolist())\n",
    "test_labels = np.array(test_df['label_encoded'].astype(int).tolist())\n",
    "\n",
    "print(f\"Train labels shape: {train_labels.shape}\")\n",
    "print(f\"Val labels shape: {val_labels.shape}\")\n",
    "print(f\"Test labels shape: {test_labels.shape}\")\n",
    "print(f\"\\nLabel distribution (Train): {np.bincount(train_labels)}\")\n",
    "print(f\"Label distribution (Val): {np.bincount(val_labels)}\")\n",
    "print(f\"Label distribution (Test): {np.bincount(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab070f4e",
   "metadata": {},
   "source": [
    "## 10. Load SinBERT Model for Sequence Classification\n",
    "\n",
    "Note: SinBERT-large is originally trained as a Masked Language Model. We'll adapt it for sequence classification by loading the base model and adding a classification head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1b38fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SinBERT model configuration\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Update config for sequence classification\n",
    "config.num_labels = 2  # Binary classification: HUMAN (0) vs AI (1)\n",
    "\n",
    "# Load pre-trained SinBERT model for sequence classification\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    config=config,\n",
    "    from_pt=True  # Convert from PyTorch if needed\n",
    ")\n",
    "\n",
    "print(f\"✓ SinBERT model loaded: {MODEL_NAME}\")\n",
    "print(f\"Number of parameters: {model.num_parameters():,}\")\n",
    "print(f\"Model type: {type(model).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdf287e",
   "metadata": {},
   "source": [
    "## 11. Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22781557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration with regularization\n",
    "LEARNING_RATE = 2e-5\n",
    "EPOCHS = 3\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "\n",
    "# Compile model\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    epsilon=1e-8,\n",
    "    clipnorm=1.0  # Gradient clipping to prevent exploding gradients\n",
    ")\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True\n",
    ")\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=[metric]\n",
    ")\n",
    "\n",
    "print(\"✓ Model compiled successfully with regularization!\")\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch Size: {TRAIN_BATCH_SIZE}\")\n",
    "print(f\"  Max Length: {MAX_LENGTH}\")\n",
    "print(f\"  Gradient Clipping: 1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4680c3f",
   "metadata": {},
   "source": [
    "## 12. Set Up Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771bd893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Create callbacks for training\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=2,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=1,\n",
    "        verbose=1,\n",
    "        min_lr=1e-7\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='models/sinbert_checkpoint.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"✓ Callbacks configured:\")\n",
    "print(\"  - Early Stopping (patience=2)\")\n",
    "print(\"  - Learning Rate Reduction (factor=0.5, patience=1)\")\n",
    "print(\"  - Model Checkpoint (best validation accuracy)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37f011c",
   "metadata": {},
   "source": [
    "## 13. Train the SinBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfae568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting Training...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "history = model.fit(\n",
    "    train_inputs,\n",
    "    train_labels,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    validation_data=(val_inputs, val_labels),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ Training Complete!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Print training summary\n",
    "print(f\"\\nTraining Summary:\")\n",
    "print(f\"  Best Epoch: {np.argmax(history.history['val_accuracy']) + 1}\")\n",
    "print(f\"  Best Val Accuracy: {max(history.history['val_accuracy']):.4f}\")\n",
    "print(f\"  Final Train Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"  Final Val Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"  Total Epochs Run: {len(history.history['accuracy'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32790372",
   "metadata": {},
   "source": [
    "## 14. Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050f8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model directory if it doesn't exist\n",
    "MODEL_SAVE_PATH = \"models/sinbert_sinhala_classifier/\"\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(MODEL_SAVE_PATH)\n",
    "print(f\"✓ Model saved to {MODEL_SAVE_PATH}\")\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(MODEL_SAVE_PATH)\n",
    "print(f\"✓ Tokenizer saved to {MODEL_SAVE_PATH}\")\n",
    "\n",
    "# Save training configuration\n",
    "config = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'max_length': MAX_LENGTH,\n",
    "    'batch_size': TRAIN_BATCH_SIZE,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'epochs': EPOCHS,\n",
    "    'label_mapping': label_mapping\n",
    "}\n",
    "\n",
    "with open(os.path.join(MODEL_SAVE_PATH, 'training_config.json'), 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"✓ Configuration saved to {MODEL_SAVE_PATH}training_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105a66fa",
   "metadata": {},
   "source": [
    "## 15. Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e278b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "print(\"\\nEvaluating on Validation Set...\")\n",
    "val_loss, val_accuracy = model.evaluate(val_inputs, val_labels, batch_size=32, verbose=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"VALIDATION SET RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Loss: {val_loss:.4f}\")\n",
    "print(f\"Accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d65721",
   "metadata": {},
   "source": [
    "## 16. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e666aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set with detailed diagnostics\n",
    "print(\"\\nEvaluating on Test Set...\")\n",
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_labels, batch_size=32, verbose=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Loss: {test_loss:.4f}\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Additional diagnostics\n",
    "print(f\"\\nTest Set Size: {len(test_labels)} samples\")\n",
    "print(f\"  HUMAN samples: {np.sum(test_labels == 0)} ({np.sum(test_labels == 0)/len(test_labels)*100:.1f}%)\")\n",
    "print(f\"  AI samples: {np.sum(test_labels == 1)} ({np.sum(test_labels == 1)/len(test_labels)*100:.1f}%)\")\n",
    "\n",
    "# Check for overfitting\n",
    "if 'val_accuracy' in history.history:\n",
    "    final_train_acc = history.history['accuracy'][-1]\n",
    "    final_val_acc = history.history['val_accuracy'][-1]\n",
    "    acc_gap = final_train_acc - final_val_acc\n",
    "    print(f\"\\nOverfitting Check:\")\n",
    "    print(f\"  Final Train Accuracy: {final_train_acc:.4f}\")\n",
    "    print(f\"  Final Val Accuracy: {final_val_acc:.4f}\")\n",
    "    print(f\"  Accuracy Gap: {acc_gap:.4f}\")\n",
    "    if acc_gap > 0.05:\n",
    "        print(f\"  ⚠️ Warning: Possible overfitting detected (gap > 5%)\")\n",
    "    else:\n",
    "        print(f\"  ✓ No significant overfitting detected\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efddf0d8",
   "metadata": {},
   "source": [
    "## 17. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45533ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2.5, marker='o')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2.5, marker='s')\n",
    "plt.title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss', linewidth=2.5, marker='o')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2.5, marker='s')\n",
    "plt.title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/sinbert_training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Training history plot saved to results/sinbert_training_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741bedf9",
   "metadata": {},
   "source": [
    "## 18. Generate Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "print(\"Generating predictions on test set...\")\n",
    "predictions = model.predict(test_inputs, batch_size=32, verbose=0)\n",
    "\n",
    "# Get predicted labels\n",
    "predicted_labels = np.argmax(predictions.logits, axis=1)\n",
    "\n",
    "# Get prediction probabilities\n",
    "probabilities = tf.nn.softmax(predictions.logits).numpy()\n",
    "positive_class_probs = probabilities[:, 1]  # Probability for AI class\n",
    "\n",
    "print(f\"✓ Predictions generated for {len(predicted_labels)} samples\")\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(f\"  HUMAN: {np.sum(predicted_labels == 0)}\")\n",
    "print(f\"  AI: {np.sum(predicted_labels == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beafb52d",
   "metadata": {},
   "source": [
    "## 19. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc56e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix with detailed analysis\n",
    "cm = confusion_matrix(test_labels, predicted_labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=['HUMAN', 'AI']\n",
    ")\n",
    "disp.plot(cmap='Blues', values_format='d', ax=plt.gca())\n",
    "\n",
    "plt.title('Confusion Matrix - SinBERT Sinhala Classifier', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/sinbert_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Confusion matrix saved to results/sinbert_confusion_matrix.png\")\n",
    "\n",
    "# Print confusion matrix values with percentages\n",
    "total = cm.sum()\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Confusion Matrix Analysis\")\n",
    "print(\"=\"*60)\n",
    "print(f\"True Negatives (HUMAN→HUMAN): {tn:4d} ({tn/total*100:.1f}%)\")\n",
    "print(f\"False Positives (HUMAN→AI):   {fp:4d} ({fp/total*100:.1f}%)\")\n",
    "print(f\"False Negatives (AI→HUMAN):   {fn:4d} ({fn/total*100:.1f}%)\")\n",
    "print(f\"True Positives (AI→AI):       {tp:4d} ({tp/total*100:.1f}%)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate error rates\n",
    "print(f\"\\nError Analysis:\")\n",
    "print(f\"  False Positive Rate: {fp/(fp+tn):.4f} ({fp/(fp+tn)*100:.2f}%)\")\n",
    "print(f\"  False Negative Rate: {fn/(fn+tp):.4f} ({fn/(fn+tp)*100:.2f}%)\")\n",
    "print(f\"  Misclassification Rate: {(fp+fn)/total:.4f} ({(fp+fn)/total*100:.2f}%)\")\n",
    "\n",
    "# Identify most common error\n",
    "if fp > fn:\n",
    "    print(f\"  ⚠️ Model tends to over-predict AI (more false positives)\")\n",
    "elif fn > fp:\n",
    "    print(f\"  ⚠️ Model tends to under-predict AI (more false negatives)\")\n",
    "else:\n",
    "    print(f\"  ✓ Balanced error distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeefba46",
   "metadata": {},
   "source": [
    "## 20. ROC Curve and AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e863a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve and AUC with improved diagnostics\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure probabilities are numpy arrays\n",
    "if hasattr(positive_class_probs, 'numpy'):\n",
    "    probs_np = positive_class_probs.numpy()\n",
    "else:\n",
    "    probs_np = np.array(positive_class_probs)\n",
    "\n",
    "# Clip probabilities to valid range\n",
    "probs_np = np.clip(probs_np, 0, 1)\n",
    "\n",
    "# For binary classification, determine which class is AI\n",
    "ai_class_idx = label_mapping['AI']  # Should be 1\n",
    "human_class_idx = label_mapping['HUMAN']  # Should be 0\n",
    "\n",
    "print(f\"AI index: {ai_class_idx}, HUMAN index: {human_class_idx}\")\n",
    "print(f\"Probability range: [{probs_np.min():.6f}, {probs_np.max():.6f}]\")\n",
    "print(f\"Mean prob when true=AI:    {probs_np[test_labels == ai_class_idx].mean():.6f}\")\n",
    "print(f\"Mean prob when true=HUMAN: {probs_np[test_labels == human_class_idx].mean():.6f}\")\n",
    "print(f\"Unique probability values: {len(np.unique(probs_np))}\")\n",
    "\n",
    "# Calculate ROC curve using AI as positive class\n",
    "fpr, tpr, thresholds = roc_curve(\n",
    "    y_true=test_labels,\n",
    "    y_score=probs_np,\n",
    "    pos_label=ai_class_idx\n",
    ")\n",
    "auc_score = roc_auc_score(test_labels, probs_np)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, label=f'SinBERT (AUC = {auc_score:.4f})', linewidth=3, color='#2E86DE')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', linewidth=2, label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curve - SinBERT Sinhala Classifier', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/sinbert_roc_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ ROC curve saved to results/sinbert_roc_curve.png\")\n",
    "print(f\"\\nAUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# Additional diagnostics\n",
    "print(f\"\\nROC Curve Diagnostics:\")\n",
    "print(f\"  Number of thresholds: {len(thresholds)}\")\n",
    "print(f\"  Threshold range: [{thresholds.min():.6f}, {thresholds.max():.6f}]\")\n",
    "print(f\"  Best threshold (Youden's J): {thresholds[np.argmax(tpr - fpr)]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793f61ba",
   "metadata": {},
   "source": [
    "## 21. Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ac7baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision-recall curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "precision, recall, pr_thresholds = precision_recall_curve(test_labels, positive_class_probs)\n",
    "avg_precision = average_precision_score(test_labels, positive_class_probs)\n",
    "\n",
    "# Plot precision-recall curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recall, precision, linewidth=3, color='#10AC84', label=f'SinBERT (AP = {avg_precision:.4f})')\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.title('Precision-Recall Curve - SinBERT Sinhala Classifier', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.legend(loc='lower left', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/sinbert_precision_recall_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Precision-Recall curve saved to results/sinbert_precision_recall_curve.png\")\n",
    "print(f\"\\nAverage Precision Score: {avg_precision:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4294c4c9",
   "metadata": {},
   "source": [
    "## 22. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc337a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "report = classification_report(\n",
    "    test_labels,\n",
    "    predicted_labels,\n",
    "    target_names=['HUMAN', 'AI'],\n",
    "    digits=4\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASSIFICATION REPORT - TEST SET\")\n",
    "print(\"=\"*70)\n",
    "print(report)\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save report to file\n",
    "with open('results/sinbert_classification_report.txt', 'w') as f:\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"CLASSIFICATION REPORT - SinBERT Sinhala Classifier\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    f.write(report)\n",
    "    f.write(\"\\n\" + \"=\"*70)\n",
    "\n",
    "print(\"\\n✓ Classification report saved to results/sinbert_classification_report.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d90728",
   "metadata": {},
   "source": [
    "## 23. Detailed Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "precision = precision_score(test_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(test_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(test_labels, predicted_labels, average='weighted')\n",
    "\n",
    "# Class-specific metrics\n",
    "precision_per_class = precision_score(test_labels, predicted_labels, average=None)\n",
    "recall_per_class = recall_score(test_labels, predicted_labels, average=None)\n",
    "f1_per_class = f1_score(test_labels, predicted_labels, average=None)\n",
    "\n",
    "# Create summary DataFrame\n",
    "metrics_summary = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Test Accuracy',\n",
    "        'Test Loss',\n",
    "        'AUC Score',\n",
    "        'Average Precision',\n",
    "        'Weighted Precision',\n",
    "        'Weighted Recall',\n",
    "        'Weighted F1-Score',\n",
    "        'HUMAN - Precision',\n",
    "        'HUMAN - Recall',\n",
    "        'HUMAN - F1-Score',\n",
    "        'AI - Precision',\n",
    "        'AI - Recall',\n",
    "        'AI - F1-Score'\n",
    "    ],\n",
    "    'Value': [\n",
    "        f'{accuracy:.4f}',\n",
    "        f'{test_loss:.4f}',\n",
    "        f'{auc_score:.4f}',\n",
    "        f'{avg_precision:.4f}',\n",
    "        f'{precision:.4f}',\n",
    "        f'{recall:.4f}',\n",
    "        f'{f1:.4f}',\n",
    "        f'{precision_per_class[0]:.4f}',\n",
    "        f'{recall_per_class[0]:.4f}',\n",
    "        f'{f1_per_class[0]:.4f}',\n",
    "        f'{precision_per_class[1]:.4f}',\n",
    "        f'{recall_per_class[1]:.4f}',\n",
    "        f'{f1_per_class[1]:.4f}'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED PERFORMANCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(metrics_summary.to_string(index=False))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save metrics\n",
    "metrics_summary.to_csv('results/sinbert_performance_metrics.csv', index=False)\n",
    "print(\"\\n✓ Metrics saved to results/sinbert_performance_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67d6021",
   "metadata": {},
   "source": [
    "## 24. Test Model on Sample Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce558ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text, model, tokenizer, max_length=256):\n",
    "    \"\"\"\n",
    "    Predict if a given text is HUMAN or AI-generated.\n",
    "    Returns prediction and confidence score.\n",
    "    \"\"\"\n",
    "    # Preprocess text\n",
    "    processed_text = preprocess_sinhala_text(text)\n",
    "\n",
    "    # Tokenize\n",
    "    encoding = tokenizer(\n",
    "        [processed_text],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "\n",
    "    # Predict\n",
    "    outputs = model(encoding)\n",
    "    probs = tf.nn.softmax(outputs.logits, axis=1).numpy()[0]\n",
    "\n",
    "    predicted_label = np.argmax(probs)\n",
    "    confidence = probs[predicted_label]\n",
    "\n",
    "    return {\n",
    "        'label': reverse_mapping[predicted_label],\n",
    "        'confidence': float(confidence),\n",
    "        'human_prob': float(probs[0]),\n",
    "        'ai_prob': float(probs[1])\n",
    "    }\n",
    "\n",
    "# Test on sample texts from test set\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "sample_indices = np.random.choice(len(test_df), 5, replace=False)\n",
    "\n",
    "correct_predictions = 0\n",
    "for i, idx in enumerate(sample_indices, 1):\n",
    "    text = test_df.iloc[idx]['text']\n",
    "    true_label = test_df.iloc[idx]['label']\n",
    "\n",
    "    result = predict_text(text, model, tokenizer, MAX_LENGTH)\n",
    "    is_correct = result['label'] == true_label\n",
    "    correct_predictions += is_correct\n",
    "\n",
    "    status = \"✓\" if is_correct else \"✗\"\n",
    "    print(f\"\\n{status} Sample {i}:\")\n",
    "    print(f\"Text: {text[:100]}...\")\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted: {result['label']} (Confidence: {result['confidence']:.2%})\")\n",
    "    print(f\"  HUMAN: {result['human_prob']:.2%} | AI: {result['ai_prob']:.2%}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "print(f\"\\nSample Accuracy: {correct_predictions}/{len(sample_indices)} ({correct_predictions/len(sample_indices)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e85275a",
   "metadata": {},
   "source": [
    "## 25. Model Summary and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b268186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SinBERT SINHALA CLASSIFIER - FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nModel: {MODEL_NAME}\")\n",
    "print(f\"Parameters: {model.num_parameters():,}\")\n",
    "print(f\"Max Sequence Length: {MAX_LENGTH}\")\n",
    "print(f\"\\nDataset Sizes:\")\n",
    "print(f\"  Training: {len(train_df):,} samples\")\n",
    "print(f\"  Validation: {len(val_df):,} samples\")\n",
    "print(f\"  Test: {len(test_df):,} samples\")\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch Size: {TRAIN_BATCH_SIZE}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "print(f\"  AUC Score: {auc_score:.4f}\")\n",
    "print(f\"  Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"  F1-Score: {f1:.4f}\")\n",
    "print(f\"\\nModel saved to: {MODEL_SAVE_PATH}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n✓ All tasks completed successfully!\")\n",
    "print(\"\\nNote: SinBERT-large is specifically trained on Sinhala data, which may provide\")\n",
    "print(\"better performance compared to multilingual models like mBERT for Sinhala text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7081e1b3",
   "metadata": {},
   "source": [
    "## 26. Download Trained Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "# Define paths\n",
    "folder_path = 'models/sinbert_sinhala_classifier'\n",
    "output_filename = 'sinbert_sinhala_classifier'\n",
    "\n",
    "# Zip the folder\n",
    "shutil.make_archive(output_filename, 'zip', folder_path)\n",
    "print(f\"Zipped {folder_path} to {output_filename}.zip\")\n",
    "\n",
    "# Download the zip file\n",
    "files.download(f\"{output_filename}.zip\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
