{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "357e5518",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/movindugunarathna/sinXdetect/blob/main/ml/sinberto_text_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f7c70",
   "metadata": {},
   "source": [
    "# SinBerto Sinhala Text Classifier\n",
    "This notebook trains a binary text classifier using the SinBerto model (Kalindu/SinBerto) to detect AI-generated vs Human-written Sinhala text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c9ddcd",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209fd9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q tf-keras\n",
    "%pip install -q transformers\n",
    "%pip install -q datasets\n",
    "%pip install -q nltk\n",
    "%pip install -q scikit-learn\n",
    "%pip install -q matplotlib\n",
    "%pip install -q gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cebcd8",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Suppress TensorFlow deprecation warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50405bf7",
   "metadata": {},
   "source": [
    "## 3. Load Dataset from JSONL Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05675104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gdown\n",
    "\n",
    "# URL of the dataset folder\n",
    "url = 'https://drive.google.com/drive/folders/1TbQbDcHKhVurAJIOekhXysMrc1JpBpyg?usp=sharing'\n",
    "output_folder = 'dataset'\n",
    "\n",
    "# Download the folder from Google Drive if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    print(\"Downloading dataset...\")\n",
    "    gdown.download_folder(url, output=output_folder, quiet=False, use_cookies=False)\n",
    "\n",
    "def load_jsonl(filepath):\n",
    "    \"\"\"Load data from JSONL file\"\"\"\n",
    "    data = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "# Load training, validation, and test datasets\n",
    "train_data = load_jsonl(os.path.join(output_folder, 'train.jsonl'))\n",
    "val_data = load_jsonl(os.path.join(output_folder, 'val.jsonl'))\n",
    "test_data = load_jsonl(os.path.join(output_folder, 'test.jsonl'))\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Testing set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a33e109",
   "metadata": {},
   "source": [
    "## 4. Convert JSONL to DataFrame and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a783bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "train_df = pd.DataFrame(train_data)\n",
    "val_df = pd.DataFrame(val_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Display sample data\n",
    "print(\"Sample training data:\")\n",
    "print(train_df[['text', 'label']].head())\n",
    "print(f\"\\nLabel value counts (Train):\")\n",
    "print(train_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e4186",
   "metadata": {},
   "source": [
    "## 5. Map Labels to Numeric Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6428d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label mapping\n",
    "label_mapping = {'HUMAN': 0, 'AI': 1}\n",
    "reverse_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Map labels to numeric values\n",
    "train_df['label_encoded'] = train_df['label'].map(label_mapping)\n",
    "val_df['label_encoded'] = val_df['label'].map(label_mapping)\n",
    "test_df['label_encoded'] = test_df['label'].map(label_mapping)\n",
    "\n",
    "# Check for any unmapped values\n",
    "print(f\"Train - Unmapped labels: {train_df['label_encoded'].isna().sum()}\")\n",
    "print(f\"Val - Unmapped labels: {val_df['label_encoded'].isna().sum()}\")\n",
    "print(f\"Test - Unmapped labels: {test_df['label_encoded'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a2506",
   "metadata": {},
   "source": [
    "## 6. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eae9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "# Sinhala-focused normalization & contraction expansion\n",
    "\n",
    "def expand_contractions(text):\n",
    "    \"\"\"\n",
    "    Normalize Sinhala text and expand a small set of common colloquial contractions.\n",
    "    - NFC Unicode normalization (avoids mixed composition forms)\n",
    "    - Remove Zero-Width Joiner/Non-Joiner which can appear in Sinhala typing\n",
    "    - Expand a curated list of common colloquial forms to their standard forms\n",
    "    Note: This list is intentionally conservative to avoid changing semantics.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    # Normalize to NFC to standardize diacritics\n",
    "    text = unicodedata.normalize('NFC', text)\n",
    "\n",
    "    # Remove zero-width characters often accidentally present\n",
    "    text = text.replace('\\u200c', '').replace('\\u200d', '')  # ZWNJ/ZWJ\n",
    "\n",
    "    # Conservative Sinhala \"contractions\" / colloquial expansions\n",
    "    contractions_si = {\n",
    "        # Negation forms\n",
    "        'නෑ': 'නැහැ',\n",
    "        'බෑ': 'බැහැ',\n",
    "        # Colloquial vowels / emphasis\n",
    "        'දැං': 'දැන්',\n",
    "        'කොහේද': 'කොහෙද',\n",
    "        'මොකෝ': 'මොකද',\n",
    "        # Common short forms ending with \"ෙ\" to \"ේ\" (targeted words only)\n",
    "        'ඇතුලෙ': 'ඇතුලේ',\n",
    "        'බාහිරෙ': 'බාහිරේ',\n",
    "        'වැඩෙ': 'වැඩේ',\n",
    "        'රජයෙ': 'රජයේ',\n",
    "        'යාලුවෙ': 'යාලුවේ',\n",
    "    }\n",
    "\n",
    "    # Apply word-boundary replacements for items above\n",
    "    for contraction, expanded in contractions_si.items():\n",
    "        text = re.sub(r\"\\b\" + re.escape(contraction) + r\"\\b\", expanded, text)\n",
    "\n",
    "    # Targeted possessive expansions (avoid generic \"ගෙ\" → \"ගේ\" to not corrupt 'ගෙදර')\n",
    "    text = re.sub(r\"\\bමගෙ\\b\", \"මගේ\", text)\n",
    "    text = re.sub(r\"\\bඔයාගෙ\\b\", \"ඔයාගේ\", text)\n",
    "    text = re.sub(r\"\\bඔගෙ\\b\", \"ඔගේ\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply expansion of contractions using Sinhala-focused normalization\n",
    "print(\"Preprocessing training data (Sinhala normalization)...\")\n",
    "train_df['expanded_text'] = train_df['text'].apply(expand_contractions)\n",
    "\n",
    "print(\"Preprocessing validation data (Sinhala normalization)...\")\n",
    "val_df['expanded_text'] = val_df['text'].apply(expand_contractions)\n",
    "\n",
    "print(\"Preprocessing test data (Sinhala normalization)...\")\n",
    "test_df['expanded_text'] = test_df['text'].apply(expand_contractions)\n",
    "\n",
    "print(\"Preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53f6965",
   "metadata": {},
   "source": [
    "## 7. Load SinBerto Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e6d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SinBerto tokenizer (Sinhala-specific BERT model)\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('Kalindu/SinBerto')\n",
    "print(\"SinBerto tokenizer loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51cb150",
   "metadata": {},
   "source": [
    "## 8. Tokenize and Encode Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0550668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode the text data using tokenizer in batches to avoid memory spikes\n",
    "print(\"Tokenizing data in batches...\")\n",
    "\n",
    "def tokenize_in_batches(texts, tokenizer, batch_size=32, max_length=512):\n",
    "    \"\"\"Tokenize a list of texts in small batches and return numpy arrays.\n",
    "    Returns a dict with 'input_ids' and 'attention_mask' as numpy arrays.\n",
    "    Pads every batch to `max_length` so concatenation shapes match.\n",
    "    \"\"\"\n",
    "    input_ids_parts = []\n",
    "    attention_mask_parts = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(\n",
    "            batch,\n",
    "            padding='max_length',   # pad each batch to the fixed max_length\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        # Convert to numpy to keep memory usage predictable and avoid nested lists\n",
    "        ids = enc['input_ids'].numpy()\n",
    "        mask = enc['attention_mask'].numpy()\n",
    "\n",
    "        # Sanity check: ensure shape[1] == max_length\n",
    "        if ids.shape[1] != max_length:\n",
    "            # If tokenizer produced a different length for some reason, force-pad/truncate\n",
    "            ids = np.pad(ids, ((0,0),(0,max_length-ids.shape[1])), constant_values=0)[:,:max_length]\n",
    "            mask = np.pad(mask, ((0,0),(0,max_length-mask.shape[1])), constant_values=0)[:,:max_length]\n",
    "\n",
    "        input_ids_parts.append(ids)\n",
    "        attention_mask_parts.append(mask)\n",
    "\n",
    "    input_ids = np.concatenate(input_ids_parts, axis=0)\n",
    "    attention_mask = np.concatenate(attention_mask_parts, axis=0)\n",
    "\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "# Run batched tokenization\n",
    "train_encodings = tokenize_in_batches(train_df['expanded_text'].tolist(), tokenizer, batch_size=32)\n",
    "val_encodings = tokenize_in_batches(val_df['expanded_text'].tolist(), tokenizer, batch_size=32)\n",
    "test_encodings = tokenize_in_batches(test_df['expanded_text'].tolist(), tokenizer, batch_size=32)\n",
    "\n",
    "print(\"Tokenization complete!\")\n",
    "print(f\"Training encodings shape: {train_encodings['input_ids'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850af665",
   "metadata": {},
   "source": [
    "## 9. Prepare Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3283b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract input arrays and convert labels to numpy arrays\n",
    "train_inputs = {\n",
    "    'input_ids': train_encodings['input_ids'],\n",
    "    'attention_mask': train_encodings['attention_mask']\n",
    "}\n",
    "val_inputs = {\n",
    "    'input_ids': val_encodings['input_ids'],\n",
    "    'attention_mask': val_encodings['attention_mask']\n",
    "}\n",
    "test_inputs = {\n",
    "    'input_ids': test_encodings['input_ids'],\n",
    "    'attention_mask': test_encodings['attention_mask']\n",
    "}\n",
    "\n",
    "# Convert labels to numpy arrays\n",
    "train_labels = np.array(train_df['label_encoded'].astype(int).tolist())\n",
    "val_labels = np.array(val_df['label_encoded'].astype(int).tolist())\n",
    "test_labels = np.array(test_df['label_encoded'].astype(int).tolist())\n",
    "\n",
    "print(f\"Train labels shape: {train_labels.shape}\")\n",
    "print(f\"Val labels shape: {val_labels.shape}\")\n",
    "print(f\"Test labels shape: {test_labels.shape}\")\n",
    "print(f\"\\nLabel distribution (Train): {np.bincount(train_labels)}\")\n",
    "print(f\"Label distribution (Val): {np.bincount(val_labels)}\")\n",
    "print(f\"Label distribution (Test): {np.bincount(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27089e5d",
   "metadata": {},
   "source": [
    "## 10. Define SinBerto Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef073ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained SinBerto model for sequence classification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    'Kalindu/SinBerto',\n",
    "    num_labels=2  # Binary classification: HUMAN (0) vs AI (1)\n",
    ")\n",
    "\n",
    "print(\"SinBerto model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fad63f",
   "metadata": {},
   "source": [
    "## 11. Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca40b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=[metric]\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")\n",
    "print(\"\\nModel Summary:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cace4c1e",
   "metadata": {},
   "source": [
    "## 12. Train the SinBerto Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874cf6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SinBerto model\n",
    "print(\"Training the model...\")\n",
    "history = model.fit(\n",
    "    train_inputs,\n",
    "    train_labels,\n",
    "    epochs=3,\n",
    "    batch_size=16,\n",
    "    validation_data=(val_inputs, val_labels),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7375bc0",
   "metadata": {},
   "source": [
    "## 13. Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3050b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire trained model\n",
    "model.save_pretrained(\"models/sinberto_sinhala_classifier/\")\n",
    "print(\"Model saved to models/sinberto_sinhala_classifier/\")\n",
    "\n",
    "# Also save the tokenizer\n",
    "tokenizer.save_pretrained(\"models/sinberto_sinhala_classifier/\")\n",
    "print(\"Tokenizer saved to models/sinberto_sinhala_classifier/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d2c6cf",
   "metadata": {},
   "source": [
    "## 14. Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dd76b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(val_inputs, val_labels, verbose=0)\n",
    "print(f'Validation Loss: {val_loss:.4f}')\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f399030",
   "metadata": {},
   "source": [
    "## 15. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_labels, verbose=0)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c324774e",
   "metadata": {},
   "source": [
    "## 16. Plot Training and Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af21952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "plt.title('Training and Validation Accuracy', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "plt.title('Training and Validation Loss', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/sinberto_training_history.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training history plot saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb865288",
   "metadata": {},
   "source": [
    "## 17. Generate Predictions and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c6040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for the test set\n",
    "predictions = model.predict(test_inputs)\n",
    "predicted_labels = np.argmax(predictions.logits, axis=1)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(test_labels, predicted_labels)\n",
    "\n",
    "# Display confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['HUMAN', 'AI'])\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "plt.title('Confusion Matrix - SinBerto Text Classification', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/sinberto_confusion_matrix.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion matrix saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e58d9",
   "metadata": {},
   "source": [
    "## 18. Calculate ROC Curve and AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621f4cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities for positive class (AI)\n",
    "probabilities = tf.nn.softmax(predictions.logits)[:, 1]\n",
    "\n",
    "# Calculate AUC score\n",
    "auc_score = roc_auc_score(test_labels, probabilities)\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(test_labels, probabilities)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc_score:.4f}', linewidth=2, color='blue')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - SinBerto Text Classification', fontsize=12, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/sinberto_roc_curve.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feec17e",
   "metadata": {},
   "source": [
    "## 19. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b85137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate detailed classification report\n",
    "report = classification_report(\n",
    "    test_labels,\n",
    "    predicted_labels,\n",
    "    target_names=['HUMAN', 'AI'],\n",
    "    digits=4\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT - TEST SET\")\n",
    "print(\"=\"*60)\n",
    "print(report)\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcdc60",
   "metadata": {},
   "source": [
    "## 20. Summary of Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c7b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary of model performance\n",
    "summary_data = {\n",
    "    'Metric': ['Test Accuracy', 'Test Loss', 'AUC Score'],\n",
    "    'Value': [f'{test_accuracy:.4f}', f'{test_loss:.4f}', f'{auc_score:.4f}']\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv('results/sinberto_model_performance_summary.csv', index=False)\n",
    "print(\"\\nPerformance summary saved to results/sinberto_model_performance_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9937a02",
   "metadata": {},
   "source": [
    "## 21. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c77cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "\n",
    "# Define constants used in training\n",
    "MODEL_NAME = \"Kalindu/SinBerto\"\n",
    "MAX_LENGTH = 512\n",
    "EPOCHS = 3\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "MODEL_SAVE_PATH = \"models/sinberto_sinhala_classifier/\"\n",
    "\n",
    "# Calculate additional metrics needed for the summary\n",
    "f1 = f1_score(test_labels, predicted_labels)\n",
    "avg_precision = average_precision_score(test_labels, probabilities)\n",
    "accuracy = test_accuracy\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SINBERTO SINHALA CLASSIFIER - FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nModel: {MODEL_NAME}\")\n",
    "print(f\"Parameters: {model.count_params():,}\")\n",
    "print(f\"Max Sequence Length: {MAX_LENGTH}\")\n",
    "print(f\"\\nDataset Sizes:\")\n",
    "print(f\"  Training: {len(train_df):,} samples\")\n",
    "print(f\"  Validation: {len(val_df):,} samples\")\n",
    "print(f\"  Test: {len(test_df):,} samples\")\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch Size: {TRAIN_BATCH_SIZE}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "print(f\"  AUC Score: {auc_score:.4f}\")\n",
    "print(f\"  Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"  F1-Score: {f1:.4f}\")\n",
    "print(f\"\\nModel saved to: {MODEL_SAVE_PATH}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n✓ All tasks completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eafee4",
   "metadata": {},
   "source": [
    "## 22. Download Model (Optional - for Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b44f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "# Define the folder to zip and the output filename\n",
    "folder_path = 'models/sinberto_sinhala_classifier/'\n",
    "zip_filename = 'sinberto_sinhala_classifier'\n",
    "\n",
    "# Create a zip archive\n",
    "shutil.make_archive(zip_filename, 'zip', folder_path)\n",
    "print(f\"Created zip file: {zip_filename}.zip\")\n",
    "\n",
    "# Download the zip file\n",
    "files.download(f'{zip_filename}.zip')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
